=====================
Configuration Options
=====================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Various configuration options are available for the MongoDB Spark
Connector.

Specify Configuration
---------------------

Via ``SparkConf``
~~~~~~~~~~~~~~~~~

You can specify these options via ``SparkConf`` using the ``--conf``
setting or the ``$SPARK_HOME/conf/spark-default.conf`` file, and
MongoDB Spark Connector will use the settings in ``SparkConf`` as the
defaults.

.. important::

   When setting configurations via ``SparkConf``, you must prefix the
   configuration options. Refer to the configuration sections for the
   specific prefix.

Via ``ReadConfig`` and ``WriteConfig``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Various methods in the MongoDB Connector API accept an optional
:mongo-spark:`ReadConfig
</blob/master/src/main/scala/com/mongodb/spark/config/ReadConfig.scala>`
or a :mongo-spark:`WriteConfig
</blob/master/src/main/scala/com/mongodb/spark/config/WriteConfig.scala>` object.
``ReadConfig`` and ``WriteConfig`` settings override any
corresponding settings in ``SparkConf``.
For examples, see :ref:`gs-read-config` and :ref:`gs-write-config`. For
more details, refer to the source for these methods.

Via Options Map
~~~~~~~~~~~~~~~

In the Spark API, some methods (e.g. ``DataFrameReader`` and
``DataFrameWriter``) accept options in the form of a ``Map[String,
String]``.

You can convert custom ``ReadConfig`` or ``WriteConfig`` settings into
a ``Map`` via the ``asOptions()`` method.

Via System Property
~~~~~~~~~~~~~~~~~~~

The connector provides a cache for ``MongoClients`` which can only be
configured via the System Property. See :ref:`cache-configuration`.

.. _cache-configuration:

Cache Configuration
-------------------

The MongoConnector includes a cache for MongoClients, so workers can
share the MongoClient across threads.

.. important::

   As the cache is setup before the Spark Configuration is available,
   the cache can only be configured via a System Property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - System Property name
     - Description

   * - ``mongodb.keep_alive_ms``
     - The length of time to keep a ``MongoClient`` available for sharing.

       **Default:** ``5000``

.. _explicit-conf-options:

Explicit Configuration Options
------------------------------

Explicit options override any corresponding settings in ``SparkConf``.

.. example::

   ``dfw.options("collection", "myCollection").save()`` 
   uses ``myCollection`` regardless of your ``SparkConf`` configuration.

Explicit configuration options support short form syntax.

.. example::

   dfw.options("spark.mongodb.collection", "myCollection").save()
   
   Can be written as

   dfw.options("collection", "myCollection").save()

``ConfigException``
-------------------

Configuration errors throw a ``ConfigException``.

Review your ``SparkConf``, any ``ReadConfig`` and ``WriteConfig`` 
objects you use, and any explicit configuration options you specify.

.. toctree::
   :titlesonly:

   configuration/write
   configuration/read
