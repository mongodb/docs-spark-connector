=============
Release Notes
=============

.. default-domain:: mongodb

MongoDB Connector for Spark 2.4.2
---------------------------------

*Released on June 10, 2020*

- Updated `MongoDB Java Driver
  <http://mongodb.github.io/mongo-java-driver/3.12/>`__
  to 3.12.5.
- Don't use Java SPI for the data source internally.
- Fix ``BsonOrdering`` bug for strings of different lengths.

MongoDB Connector for Spark `2.4.1`_
------------------------------------

*Released on June 6, 2019*

- Ensures nullable fields or container types accept ``null`` values.
- Added ``ReadConfig.batchSize`` property. For more information, see
  :ref:`spark-input-conf`.
- Renamed system property ``spark.mongodb.keep_alive_ms`` to
  ``mongodb.keep_alive_ms``.
- Added ``MongoDriverInformation`` to the default ``MongoClient``.
- Updated to latest Java driver (3.10.+)
- Updated ``PartitionerHelper.matchQuery`` to no longer include ``$ne``/``$exists``
  checks.
- Added logging support for partitioners and their queries.
- Added ``WriteConfig.extendedBsonTypes`` setting so users can disable
  extended BSON types when writing. For more information, see
  :ref:`spark-output-conf`.
- Added Java spi can now use short form: ``spark.read.format("mongo")``.
- ``spark.read.format("mongo")`` can be used in place of
  ``spark.read.format("com.mongodb.spark.sql")`` and
  ``spark.read.format("com.mongodb.spark.sql.DefaultSource")``.

MongoDB Connector for Spark `2.4.0`_
------------------------------------

*Released on December 7, 2018*

- Support Spark 2.4.0. Updated Spark dependency to 2.4.0.
- Ensure ``WriteConfig.ordered`` is applied to write operations.
- Updated Mongo Java Driver to 3.9.0.
- Added Scala 2.12 support.
- Fixed ``MongoSpark.toDF()`` to use the provided ``MongoConnector``.

.. _2.4.1: https://github.com/mongodb/mongo-spark/compare/2.4.0...r2.4.1
.. _2.4.0: https://github.com/mongodb/mongo-spark/compare/2.3.x...r2.4.0
