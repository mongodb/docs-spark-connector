.. _read-from-mongodb: 
.. _scala-read:
.. _java-read:
.. _scala-dataset-filters:

=================
Read from MongoDB
=================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol 

Overview
--------

.. tabs-selector:: drivers

.. tabs-drivers::

   tabs:
     - id: java-sync
       content: |

         .. include:: /java/read-from-mongodb.txt

     - id: python
       content: |

         .. include:: /python/read-from-mongodb.txt

         .. include:: /python/filters.txt

     - id: scala
       content: |

         .. include:: /scala/read-from-mongodb.txt

         .. include:: /scala/filters.txt

.. important:: Inferring the Schema of a Change Stream

   When the {+connector-short+} infers the schema of a data frame 
   read from a change stream, by default,
   it will use the schema of the underlying collection rather than that
   of the change stream. If you set the ``change.stream.publish.full.document.only``
   option to ``true``, the connector uses the schema of the 
   change stream instead.

   For more information on configuring a read operation, see the
   :ref:`spark-change-stream-conf` section of the Read Configuration Options guide.

SQL Queries
-----------

.. tabs-drivers::

   tabs:
     - id: java-sync
       content: |

         .. include:: /java/sql.txt

     - id: python
       content: |

         .. include:: /python/sql.txt

     - id: scala
       content: |

         .. include:: /scala/sql.txt
