.. _spark-write-conf:
.. _spark-streaming-write-conf:

===========================
Write Configuration Options
===========================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. _spark-streaming-output-conf:

Write Configuration
-------------------

You can configure the following properties when writing data to MongoDB in streaming mode:

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to each property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - Property name
     - Description
   
   * - ``connection.uri``
     - | **Required.**
       | The connection string configuration key.
       |
       | **Default:** ``mongodb://localhost:27017/``

   * - ``database``
     - | **Required.**
       | The database name configuration.

   * - ``collection``
     - | **Required.**
       | The collection name configuration.

   * - ``comment``
     - | The comment to append to the write operation. Comments appear in the 
         :manual:`output of the Database Profiler. </reference/database-profiler>`
       |
       | **Default:** None 

   * - ``mongoClientFactory``
     - | MongoClientFactory configuration key.
       | You can specify a custom implementation which must implement the
         ``com.mongodb.spark.sql.connector.connection.MongoClientFactory``
         interface.
       |
       | **Default:** ``com.mongodb.spark.sql.connector.connection.DefaultMongoClientFactory``
    
   * - ``checkpointLocation``
     - | The absolute file path of the directory to which the connector writes checkpoint
         information.
       |
       | For more information about checkpoints, see the
         `Spark Structured Streaming Programming Guide <https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#recovering-from-failures-with-checkpointing>`__
       | 
       | **Default:** 
   
   * - ``forceDeleteTempCheckpointLocation``
     - | A Boolean value that specifies whether to delete existing checkpoint data. 
       |
       | **Default:** 

.. _configure-streaming-output-uri:

``connection.uri`` Configuration Setting
----------------------------------------

You can set all :ref:`spark-output-conf` via the write ``connection.uri``.

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to the setting.

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/test.myCollection

The configuration corresponds to the following separate configuration
settings:

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/
   spark.mongodb.write.database=test
   spark.mongodb.write.collection=myCollection

If you specify a setting both in the ``connection.uri`` and in a separate
configuration, the ``connection.uri`` setting overrides the separate
setting. For example, in the following configuration, the
database for the connection is ``foobar``:

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/foobar
   spark.mongodb.write.database=bar
