===========================
Write Configuration Options
===========================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol


.. _configure-input-uri:

``uri`` Configuration Setting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can set all :ref:`spark-input-conf` via the input ``uri`` setting.

For example, consider the following example which sets the input
``uri`` setting via ``SparkConf``:

.. note::

   If you use ``SparkConf`` to set the connector's input configurations, 
   prefix ``spark.mongodb.input.`` to the setting.

.. code:: cfg

   spark.mongodb.input.uri=mongodb://127.0.0.1/databaseName.collectionName?readPreference=primaryPreferred

The configuration corresponds to the following separate configuration
settings:

.. code:: cfg

   spark.mongodb.input.uri=mongodb://127.0.0.1/
   spark.mongodb.input.database=databaseName
   spark.mongodb.input.collection=collectionName
   spark.mongodb.input.readPreference.name=primaryPreferred

If you specify a setting both in the ``uri`` and in a separate
configuration, the ``uri`` setting overrides the separate
setting. For example, given the following configuration, the input
database for the connection is ``foobar``:

.. code:: cfg

   spark.mongodb.input.uri=mongodb://127.0.0.1/foobar
   spark.mongodb.input.database=bar

.. _spark-output-conf:

Output Configuration
--------------------

The following options for writing to MongoDB are available:

.. note::

   If you use ``SparkConf`` to set the connector's output configurations,
   prefix ``spark.mongodb.output.`` to each property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - Property name
     - Description

   * - ``uri``
     - **Required.** 
       The connection string in the form
       ``mongodb://host:port/``. The ``host`` can be a hostname, IP
       address, or UNIX domain socket. If the connection string doesn't
       specify a ``port``, it uses the default MongoDB port, ``27017``.
       
       .. note:: 

          The other remaining options may be appended to the ``uri``
          setting. See :ref:`configure-output-uri`.

   * - ``database``
     - **Required.**
       The database name to write data.

   * - ``collection``
     - **Required.**
       The collection name to write data to

   * - ``extendedBsonTypes``
     - Enables extended BSON types when writing data to MongoDB.

       **Default:** ``true``

   * - ``localThreshold``
     - The threshold (milliseconds) for choosing a server from multiple
       MongoDB servers.

       **Default:** ``15``

   * - ``replaceDocument``
     - Replace the whole document when saving Datasets that contain an ``_id`` field.
       If false it will only update the fields in the document that match the fields in the Dataset.

       **Default:** ``true``
       
   * - ``maxBatchSize``
     - The maximum batch size for bulk operations when saving data.

       **Default:** ``512``

   * - ``writeConcern.w``
     - The write concern :ref:`w <wc-w>` value.

       **Default:** ``w: 1``
   
   * - ``writeConcern.journal``
     - The write concern :ref:`journal <wc-j>` value.

   * - ``writeConcern.wTimeoutMS``
     - The write concern :ref:`wTimeout <wc-wtimeout>` value.

   * - ``shardKey``
     - The field by which to split the collection data. The field
       should be indexed and contain unique values.

       **Default:** ``_id``

   * - ``forceInsert``
     - Forces saves to use inserts, even if a Dataset contains ``_id``.

       **Default:** ``false``

   * - ``ordered``
     - Sets the bulk operations ordered property.

       **Default:** ``true``

.. _configure-output-uri:

``uri`` Configuration Setting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can set all :ref:`spark-output-conf` via the output ``uri``.

For example, consider the following example which sets the input
``uri`` setting via ``SparkConf``:

.. note::

   If you use ``SparkConf`` to set the connector's output configurations,
   prefix ``spark.mongodb.output.`` to the setting.

.. code:: cfg

   spark.mongodb.output.uri=mongodb://127.0.0.1/test.myCollection

The configuration corresponds to the following separate configuration
settings:

.. code:: cfg

   spark.mongodb.output.uri=mongodb://127.0.0.1/
   spark.mongodb.output.database=test
   spark.mongodb.output.collection=myCollection

If you specify a setting both in the ``uri`` and in a separate
configuration, the ``uri`` setting overrides the separate
setting. For example, given the following configuration, the output
database for the connection is ``foobar``:

.. code:: cfg

   spark.mongodb.output.uri=mongodb://127.0.0.1/foobar
   spark.mongodb.output.database=bar

.. _cache-configuration:

Cache Configuration
-------------------

The MongoConnector includes a cache for MongoClients, so workers can
share the MongoClient across threads.

.. important::

   As the cache is setup before the Spark Configuration is available,
   the cache can only be configured via a System Property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - System Property name
     - Description

   * - ``mongodb.keep_alive_ms``
     - The length of time to keep a ``MongoClient`` available for sharing.

       **Default:** ``5000``
