.. _spark-write-conf:

===========================
Write Configuration Options
===========================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. _spark-output-conf:

Write Configuration
-------------------

The following options for writing to MongoDB are available:

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to each property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - Property name
     - Description

   * - ``uri``
     - **Required.** 
       The connection string in the form
       ``mongodb://host:port/``. The ``host`` can be a hostname, IP
       address, or UNIX domain socket. If the connection string doesn't
       specify a ``port``, it uses the default MongoDB port, ``27017``.
       
       .. note:: 

          The other remaining options may be appended to the ``uri``
          setting. See :ref:`configure-output-uri`.

   * - ``database``
     - **Required.**
       The database name to write data.

   * - ``collection``
     - **Required.**
       The collection name to write data to

   * - ``extendedBsonTypes``
     - Enables extended BSON types when writing data to MongoDB.

       **Default:** ``true``

   * - ``localThreshold``
     - The threshold (milliseconds) for choosing a server from multiple
       MongoDB servers.

       **Default:** ``15``

   * - ``replaceDocument``
     - Replace the whole document when saving Datasets that contain an ``_id`` field.
       If false it will only update the fields in the document that match the fields in the Dataset.

       **Default:** ``true``
       
   * - ``maxBatchSize``
     - The maximum batch size for bulk operations when saving data.

       **Default:** ``512``

   * - ``writeConcern.w``
     - The write concern :ref:`w <wc-w>` value.

       **Default:** ``w: 1``
   
   * - ``writeConcern.journal``
     - The write concern :ref:`journal <wc-j>` value.

   * - ``writeConcern.wTimeoutMS``
     - The write concern :ref:`wTimeout <wc-wtimeout>` value.

   * - ``shardKey``
     - The field by which to split the collection data. The field
       should be indexed and contain unique values.

       **Default:** ``_id``

   * - ``forceInsert``
     - Forces saves to use inserts, even if a Dataset contains ``_id``.

       **Default:** ``false``

   * - ``ordered``
     - Sets the bulk operations ordered property.

       **Default:** ``true``

.. _configure-output-uri:

``uri`` Configuration Setting
-----------------------------

You can set all :ref:`spark-output-conf` via the write ``uri``.

For example, consider the following example which sets the write
``uri`` setting via ``SparkConf``:

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to the setting.

.. code:: cfg

   spark.mongodb.write.uri=mongodb://127.0.0.1/test.myCollection

The configuration corresponds to the following separate configuration
settings:

.. code:: cfg

   spark.mongodb.write.uri=mongodb://127.0.0.1/
   spark.mongodb.write.database=test
   spark.mongodb.write.collection=myCollection

If you specify a setting both in the ``uri`` and in a separate
configuration, the ``uri`` setting overrides the separate
setting. For example, given the following configuration, the
database for the connection is ``foobar``:

.. code:: cfg

   spark.mongodb.write.uri=mongodb://127.0.0.1/foobar
   spark.mongodb.write.database=bar
