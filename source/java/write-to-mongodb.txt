To write data to MongoDB, call the ``write()`` method on your
DataFrame object. This method returns a
`DataFrameWriter <https://spark.apache.org/docs/latest/api/java>`__
object, which you can use to specify the format and other configuration settings for your
batch write operation. 

.. include:: /includes/batch-write-settings.rst

The following example creates a DataFrame from a ``json`` file and 
saves it to the MongoDB database and collection specified in ``SparkConf``:

.. code-block:: java

   Dataset<Row> dataFrame = spark.read().format("json")
                                        .load("example.json");

   dataFrame.write().format("mongodb")
                    .mode("overwrite")
                    .save();

.. include:: /includes/save-modes-tip.rst